model:
    target: enhancing.modules.stage2.transformer.CondTransformer
    params:
        code_shape: [16, 16]
        cond_key: class
        cond: 
            target: enhancing.modules.cond.dummycond.ClassCond
            params:
                image_size: 224
                class_name: ["flower"]
        stage1:
            target: enhancing.modules.stage1.vqsae.VQModel
            params:
                image_key: image
                hparams:
                    dims: [3, 192, 384, 384, 384]
                    hidden_dims: [48, 96, 96, 96]
                    stage_depths: [4, 3, 8, 3]
                    scales: [7, 2, 1, 1]
                    mlp_ratio: 3
                qparams:
                    embed_dim: 32
                    n_embed: 8192
                loss:
                    target: enhancing.losses.vqperceptual.DummyLoss
        transformer:
            target: enhancing.modules.stage2.layers.GPT
            params:
                vocab_cond_size: 1
                vocab_img_size: 8192
                embed_dim: 6144
                cond_num_tokens: 1
                img_num_tokens: 256
                n_heads: 16
                n_layers: 24       
dataset:
    target: enhancing.dataloader.DataModuleFromConfig
    params:
        batch_size: 4
        num_workers: 2
        train:
            target: enhancing.dataloader.classimage.ClassImageTrain
            params:
                root: data
                resolution: 224
                
        validation:
            target: enhancing.dataloader.classimage.ClassImageValidation
            params:
                root: data
                resolution: 224
